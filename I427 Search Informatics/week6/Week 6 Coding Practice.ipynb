{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Create a data structure that will store the file name, total word count, term frequency vector, and other data for each page. You may want to use file name as a key, or create a unique ID as key. It's your call.\n",
    "\n",
    "2) Next, extract and process the text of each document as per previous lab work (remove whitespace, tokenize, remove stopwords. Preview the document and stem all terms); BEFORE you remove the stopwords, calculate the word count and save it for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer \n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('/Users/mac/Documents/I427/week6/')\n",
    "files_dict = {}\n",
    "N = 0\n",
    "for file in files:\n",
    "    if 'txt' in file:\n",
    "        N += 1\n",
    "        with open (file,'r') as md_file:\n",
    "            content = md_file.read()\n",
    "            #remove punctuation\n",
    "            content = re.sub('[^A-Za-z0-9]+', ' ', content)\n",
    "            #remove space\n",
    "            content = nltk.word_tokenize(content.lower())\n",
    "            count = len(content)\n",
    "            files_dict[file] = {\"words_count\":count}\n",
    "            ps = PorterStemmer() \n",
    "            #remove stopwords\n",
    "            content = [word for word in content if not word in stopwords.words()]\n",
    "            #stem each word\n",
    "            content = [ps.stem(word) for word in content]\n",
    "            #count term frequency\n",
    "            words_f = dict(Counter(content))\n",
    "            for key, value in words_f.items():\n",
    "                words_f[key] = value/count\n",
    "                #words_f[key] = value\n",
    "            files_dict[file][\"tf\"] = words_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dict2 = files_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words_count': 339,\n",
       " 'tf': {'glacier': 0.029498525073746312,\n",
       "  'distinct': 0.0029498525073746312,\n",
       "  'greenland': 0.0058997050147492625,\n",
       "  'antarct': 0.0058997050147492625,\n",
       "  'ice': 0.008849557522123894,\n",
       "  'sheet': 0.008849557522123894,\n",
       "  'cover': 0.0029498525073746312,\n",
       "  'area': 0.0058997050147492625,\n",
       "  'approxim': 0.0029498525073746312,\n",
       "  '706': 0.0029498525073746312,\n",
       "  '000': 0.0058997050147492625,\n",
       "  'squar': 0.0029498525073746312,\n",
       "  'kilometr': 0.0058997050147492625,\n",
       "  'global': 0.011799410029498525,\n",
       "  '1': 0.008849557522123894,\n",
       "  'estim': 0.008849557522123894,\n",
       "  'total': 0.0058997050147492625,\n",
       "  'volum': 0.0029498525073746312,\n",
       "  '170': 0.0029498525073746312,\n",
       "  'cubic': 0.0029498525073746312,\n",
       "  '0': 0.011799410029498525,\n",
       "  '4': 0.0058997050147492625,\n",
       "  'metr': 0.008849557522123894,\n",
       "  'potenti': 0.0029498525073746312,\n",
       "  'level': 0.02064896755162242,\n",
       "  'rise': 0.011799410029498525,\n",
       "  'equival': 0.008849557522123894,\n",
       "  '2': 0.0058997050147492625,\n",
       "  'retreat': 0.0029498525073746312,\n",
       "  'thin': 0.0029498525073746312,\n",
       "  'icon': 0.0029498525073746312,\n",
       "  'climat': 0.0058997050147492625,\n",
       "  'chang': 0.011799410029498525,\n",
       "  '3': 0.0029498525073746312,\n",
       "  'affect': 0.0029498525073746312,\n",
       "  'region': 0.014749262536873156,\n",
       "  'runoff': 0.0029498525073746312,\n",
       "  'well': 0.0058997050147492625,\n",
       "  '5': 0.0029498525073746312,\n",
       "  '6': 0.0029498525073746312,\n",
       "  'past': 0.0058997050147492625,\n",
       "  'report': 0.0058997050147492625,\n",
       "  'intergovernment': 0.0029498525073746312,\n",
       "  'panel': 0.0029498525073746312,\n",
       "  'mass': 0.014749262536873156,\n",
       "  'base': 0.0058997050147492625,\n",
       "  'multipl': 0.0029498525073746312,\n",
       "  'averag': 0.0029498525073746312,\n",
       "  'interpol': 0.0029498525073746312,\n",
       "  'result': 0.008849557522123894,\n",
       "  'avail': 0.0058997050147492625,\n",
       "  'observ': 0.008849557522123894,\n",
       "  'hundr': 0.0029498525073746312,\n",
       "  'defin': 0.0029498525073746312,\n",
       "  '7': 0.0029498525073746312,\n",
       "  '10': 0.0029498525073746312,\n",
       "  'data': 0.0058997050147492625,\n",
       "  'scarc': 0.0029498525073746312,\n",
       "  'complement': 0.0029498525073746312,\n",
       "  'satellit': 0.0058997050147492625,\n",
       "  'altimetri': 0.0058997050147492625,\n",
       "  'gravimetri': 0.0058997050147492625,\n",
       "  '11': 0.0058997050147492625,\n",
       "  'approach': 0.0029498525073746312,\n",
       "  'challeng': 0.0029498525073746312,\n",
       "  'small': 0.0029498525073746312,\n",
       "  'number': 0.0029498525073746312,\n",
       "  'heterogen': 0.0029498525073746312,\n",
       "  'spatiotempor': 0.0029498525073746312,\n",
       "  'distribut': 0.0029498525073746312,\n",
       "  'situ': 0.0029498525073746312,\n",
       "  'measur': 0.0029498525073746312,\n",
       "  'seri': 0.0029498525073746312,\n",
       "  'often': 0.0029498525073746312,\n",
       "  'unknown': 0.0029498525073746312,\n",
       "  'abil': 0.0029498525073746312,\n",
       "  'repres': 0.0029498525073746312,\n",
       "  'respect': 0.0029498525073746312,\n",
       "  'mountain': 0.0058997050147492625,\n",
       "  'rang': 0.011799410029498525,\n",
       "  'spatial': 0.0029498525073746312,\n",
       "  'limit': 0.0029498525073746312,\n",
       "  'point': 0.0029498525073746312,\n",
       "  'coars': 0.0029498525073746312,\n",
       "  'resolut': 0.0029498525073746312,\n",
       "  'use': 0.0029498525073746312,\n",
       "  'extrapol': 0.0029498525073746312,\n",
       "  'glaciolog': 0.0029498525073746312,\n",
       "  'geodet': 0.0029498525073746312,\n",
       "  'show': 0.0029498525073746312,\n",
       "  'contribut': 0.011799410029498525,\n",
       "  '27': 0.0029498525073746312,\n",
       "  '22': 0.0029498525073746312,\n",
       "  'millimetr': 0.0058997050147492625,\n",
       "  'mean': 0.0029498525073746312,\n",
       "  '1961': 0.0029498525073746312,\n",
       "  '2016': 0.0058997050147492625,\n",
       "  'specif': 0.0029498525073746312,\n",
       "  'rate': 0.0058997050147492625,\n",
       "  '2006': 0.0029498525073746312,\n",
       "  'water': 0.0029498525073746312,\n",
       "  'year': 0.0058997050147492625,\n",
       "  '335': 0.0029498525073746312,\n",
       "  '144': 0.0029498525073746312,\n",
       "  'gigatonn': 0.0029498525073746312,\n",
       "  '92': 0.0029498525073746312,\n",
       "  '39': 0.0029498525073746312,\n",
       "  'although': 0.0029498525073746312,\n",
       "  'statist': 0.0029498525073746312,\n",
       "  'uncertainti': 0.0029498525073746312,\n",
       "  'overlap': 0.0029498525073746312,\n",
       "  'conclus': 0.0029498525073746312,\n",
       "  'suggest': 0.0029498525073746312,\n",
       "  'loss': 0.011799410029498525,\n",
       "  'may': 0.0029498525073746312,\n",
       "  'larger': 0.0029498525073746312,\n",
       "  'previous': 0.0029498525073746312,\n",
       "  'present': 0.0058997050147492625,\n",
       "  '12': 0.0029498525073746312,\n",
       "  'clearli': 0.0029498525073746312,\n",
       "  'exce': 0.0029498525073746312,\n",
       "  '13': 0.0029498525073746312,\n",
       "  'account': 0.0029498525073746312,\n",
       "  '25': 0.0029498525073746312,\n",
       "  '30': 0.0029498525073746312,\n",
       "  'cent': 0.0029498525073746312,\n",
       "  '14': 0.0029498525073746312,\n",
       "  'indic': 0.0029498525073746312,\n",
       "  'could': 0.0029498525073746312,\n",
       "  'almost': 0.0029498525073746312,\n",
       "  'disappear': 0.0029498525073746312,\n",
       "  'centuri': 0.0029498525073746312,\n",
       "  'heavili': 0.0029498525073746312,\n",
       "  'continu': 0.0029498525073746312,\n",
       "  'beyond': 0.0029498525073746312,\n",
       "  '2100': 0.0029498525073746312}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e.g.\n",
    "files_dict['Lab5_file7.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words_count': 339,\n",
       " 'tf': {'glacier': 10,\n",
       "  'distinct': 1,\n",
       "  'greenland': 2,\n",
       "  'antarct': 2,\n",
       "  'ice': 3,\n",
       "  'sheet': 3,\n",
       "  'cover': 1,\n",
       "  'area': 2,\n",
       "  'approxim': 1,\n",
       "  '706': 1,\n",
       "  '000': 2,\n",
       "  'squar': 1,\n",
       "  'kilometr': 2,\n",
       "  'global': 4,\n",
       "  '1': 3,\n",
       "  'estim': 3,\n",
       "  'total': 2,\n",
       "  'volum': 1,\n",
       "  '170': 1,\n",
       "  'cubic': 1,\n",
       "  '0': 4,\n",
       "  '4': 2,\n",
       "  'metr': 3,\n",
       "  'potenti': 1,\n",
       "  'level': 7,\n",
       "  'rise': 4,\n",
       "  'equival': 3,\n",
       "  '2': 2,\n",
       "  'retreat': 1,\n",
       "  'thin': 1,\n",
       "  'icon': 1,\n",
       "  'climat': 2,\n",
       "  'chang': 4,\n",
       "  '3': 1,\n",
       "  'affect': 1,\n",
       "  'region': 5,\n",
       "  'runoff': 1,\n",
       "  'well': 2,\n",
       "  '5': 1,\n",
       "  '6': 1,\n",
       "  'past': 2,\n",
       "  'report': 2,\n",
       "  'intergovernment': 1,\n",
       "  'panel': 1,\n",
       "  'mass': 5,\n",
       "  'base': 2,\n",
       "  'multipl': 1,\n",
       "  'averag': 1,\n",
       "  'interpol': 1,\n",
       "  'result': 3,\n",
       "  'avail': 2,\n",
       "  'observ': 3,\n",
       "  'hundr': 1,\n",
       "  'defin': 1,\n",
       "  '7': 1,\n",
       "  '10': 1,\n",
       "  'data': 2,\n",
       "  'scarc': 1,\n",
       "  'complement': 1,\n",
       "  'satellit': 2,\n",
       "  'altimetri': 2,\n",
       "  'gravimetri': 2,\n",
       "  '11': 2,\n",
       "  'approach': 1,\n",
       "  'challeng': 1,\n",
       "  'small': 1,\n",
       "  'number': 1,\n",
       "  'heterogen': 1,\n",
       "  'spatiotempor': 1,\n",
       "  'distribut': 1,\n",
       "  'situ': 1,\n",
       "  'measur': 1,\n",
       "  'seri': 1,\n",
       "  'often': 1,\n",
       "  'unknown': 1,\n",
       "  'abil': 1,\n",
       "  'repres': 1,\n",
       "  'respect': 1,\n",
       "  'mountain': 2,\n",
       "  'rang': 4,\n",
       "  'spatial': 1,\n",
       "  'limit': 1,\n",
       "  'point': 1,\n",
       "  'coars': 1,\n",
       "  'resolut': 1,\n",
       "  'use': 1,\n",
       "  'extrapol': 1,\n",
       "  'glaciolog': 1,\n",
       "  'geodet': 1,\n",
       "  'show': 1,\n",
       "  'contribut': 4,\n",
       "  '27': 1,\n",
       "  '22': 1,\n",
       "  'millimetr': 2,\n",
       "  'mean': 1,\n",
       "  '1961': 1,\n",
       "  '2016': 2,\n",
       "  'specif': 1,\n",
       "  'rate': 2,\n",
       "  '2006': 1,\n",
       "  'water': 1,\n",
       "  'year': 2,\n",
       "  '335': 1,\n",
       "  '144': 1,\n",
       "  'gigatonn': 1,\n",
       "  '92': 1,\n",
       "  '39': 1,\n",
       "  'although': 1,\n",
       "  'statist': 1,\n",
       "  'uncertainti': 1,\n",
       "  'overlap': 1,\n",
       "  'conclus': 1,\n",
       "  'suggest': 1,\n",
       "  'loss': 4,\n",
       "  'may': 1,\n",
       "  'larger': 1,\n",
       "  'previous': 1,\n",
       "  'present': 2,\n",
       "  '12': 1,\n",
       "  'clearli': 1,\n",
       "  'exce': 1,\n",
       "  '13': 1,\n",
       "  'account': 1,\n",
       "  '25': 1,\n",
       "  '30': 1,\n",
       "  'cent': 1,\n",
       "  '14': 1,\n",
       "  'indic': 1,\n",
       "  'could': 1,\n",
       "  'almost': 1,\n",
       "  'disappear': 1,\n",
       "  'centuri': 1,\n",
       "  'heavili': 1,\n",
       "  'continu': 1,\n",
       "  'beyond': 1,\n",
       "  '2100': 1}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e.g.\n",
    "files_dict2['Lab5_file7.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Once you've completed this step for all documents, create a list of unique terms from all the documents you are working with (make sure the list is sorted alphabetically). Using this list as a guide, create a vector (stored as a list or tuple) for each document with counts for each term in the corresponding index position of the unique term list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all terms together\n",
    "all_terms = []\n",
    "for each_file in files_dict.values():\n",
    "    full_lst = list(each_file['tf'].keys())\n",
    "    for each in full_lst:\n",
    "        all_terms.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "732"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter out duplicates\n",
    "unique_terms = set(all_terms)\n",
    "unique_terms = sorted(unique_terms)\n",
    "len(unique_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Lab5_file9.txt',\n",
       " 2: 'Lab5_file8.txt',\n",
       " 3: 'Lab5_file6.txt',\n",
       " 4: 'Lab5_file7.txt',\n",
       " 5: 'Lab5_file5.txt',\n",
       " 6: 'Lab5_file4.txt',\n",
       " 7: 'Lab5_file1.txt',\n",
       " 8: 'Lab5_file3.txt',\n",
       " 9: 'Lab5_file2.txt'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a mapping dict for reference\n",
    "mapping_dict = {}\n",
    "for key in files_dict.keys():\n",
    "        if key not in mapping_dict.values():\n",
    "            if not mapping_dict.keys():\n",
    "                mapping_dict[1] = key\n",
    "            else:\n",
    "                mapping_dict[int(max(mapping_dict.keys())+1)] = key\n",
    "mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary contains how many times all unique terms appear in each text file\n",
    "#displays 0 if terms didn't appear in the file\n",
    "tf_vector = {}\n",
    "for term in unique_terms:\n",
    "    for v in mapping_dict.values():\n",
    "        for subdicts in files_dict2[v]['tf']:\n",
    "            lst = list(files_dict2[v]['tf'].keys())\n",
    "            if term in lst:\n",
    "                tf_vector.setdefault(v, {})[term] = files_dict2[v]['tf'][term]\n",
    "            else:\n",
    "                tf_vector.setdefault(v, {})[term] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 4,\n",
       " '000': 2,\n",
       " '1': 3,\n",
       " '10': 1,\n",
       " '1000': 0,\n",
       " '11': 2,\n",
       " '12': 1,\n",
       " '13': 1,\n",
       " '14': 1,\n",
       " '144': 1,\n",
       " '1500': 0,\n",
       " '170': 1,\n",
       " '18': 0,\n",
       " '1961': 1,\n",
       " '1992': 0,\n",
       " '2': 2,\n",
       " '200': 0,\n",
       " '2006': 1,\n",
       " '2015': 0,\n",
       " '2016': 2,\n",
       " '2030': 0,\n",
       " '2100': 1,\n",
       " '21st': 0,\n",
       " '22': 1,\n",
       " '25': 1,\n",
       " '253': 0,\n",
       " '27': 1,\n",
       " '3': 1,\n",
       " '30': 1,\n",
       " '300': 0,\n",
       " '3000': 0,\n",
       " '32': 0,\n",
       " '3300': 0,\n",
       " '335': 1,\n",
       " '3500': 0,\n",
       " '3700': 0,\n",
       " '39': 1,\n",
       " '4': 2,\n",
       " '40': 0,\n",
       " '4300': 0,\n",
       " '4500': 0,\n",
       " '47': 0,\n",
       " '5': 1,\n",
       " '6': 1,\n",
       " '6000': 0,\n",
       " '6100': 0,\n",
       " '6300': 0,\n",
       " '6500': 0,\n",
       " '6700': 0,\n",
       " '7': 1,\n",
       " '706': 1,\n",
       " '73': 0,\n",
       " '7900': 0,\n",
       " '8500': 0,\n",
       " '92': 1,\n",
       " 'abil': 1,\n",
       " 'abiot': 0,\n",
       " 'abl': 0,\n",
       " 'abund': 0,\n",
       " 'access': 0,\n",
       " 'account': 1,\n",
       " 'achiev': 0,\n",
       " 'across': 0,\n",
       " 'action': 0,\n",
       " 'activ': 0,\n",
       " 'adapt': 0,\n",
       " 'addit': 0,\n",
       " 'address': 0,\n",
       " 'adopt': 0,\n",
       " 'affect': 1,\n",
       " 'afford': 0,\n",
       " 'africa': 0,\n",
       " 'agenc': 0,\n",
       " 'agenda': 0,\n",
       " 'agglom': 0,\n",
       " 'aggreg': 0,\n",
       " 'agreement': 0,\n",
       " 'agricultur': 0,\n",
       " 'allow': 0,\n",
       " 'almost': 1,\n",
       " 'along': 0,\n",
       " 'alreadi': 0,\n",
       " 'alter': 0,\n",
       " 'although': 1,\n",
       " 'altimetri': 2,\n",
       " 'ambiti': 0,\n",
       " 'amend': 0,\n",
       " 'among': 0,\n",
       " 'analysi': 0,\n",
       " 'analyz': 0,\n",
       " 'annual': 0,\n",
       " 'answer': 0,\n",
       " 'antarct': 2,\n",
       " 'anthropogen': 0,\n",
       " 'appear': 0,\n",
       " 'appli': 0,\n",
       " 'approach': 1,\n",
       " 'approxim': 1,\n",
       " 'aquat': 0,\n",
       " 'arbor': 0,\n",
       " 'archaeo': 0,\n",
       " 'archaeolog': 0,\n",
       " 'area': 2,\n",
       " 'around': 0,\n",
       " 'articl': 0,\n",
       " 'aspect': 0,\n",
       " 'aspir': 0,\n",
       " 'assess': 0,\n",
       " 'assist': 0,\n",
       " 'associ': 0,\n",
       " 'assum': 0,\n",
       " 'asynchron': 0,\n",
       " 'atmospher': 0,\n",
       " 'attent': 0,\n",
       " 'avail': 2,\n",
       " 'averag': 1,\n",
       " 'axe': 0,\n",
       " 'axi': 0,\n",
       " 'balkan': 0,\n",
       " 'base': 2,\n",
       " 'baselin': 0,\n",
       " 'basin': 0,\n",
       " 'becam': 0,\n",
       " 'beetl': 0,\n",
       " 'benefit': 0,\n",
       " 'better': 0,\n",
       " 'beyond': 1,\n",
       " 'bin': 0,\n",
       " 'biodivers': 0,\n",
       " 'biogeograph': 0,\n",
       " 'biogeographi': 0,\n",
       " 'biolog': 0,\n",
       " 'biom': 0,\n",
       " 'biotic': 0,\n",
       " 'bodi': 0,\n",
       " 'bp': 0,\n",
       " 'cal': 0,\n",
       " 'calcul': 0,\n",
       " 'call': 0,\n",
       " 'cap': 0,\n",
       " 'captur': 0,\n",
       " 'carbon': 0,\n",
       " 'cave': 0,\n",
       " 'cent': 1,\n",
       " 'centenni': 0,\n",
       " 'central': 0,\n",
       " 'centuri': 1,\n",
       " 'challeng': 1,\n",
       " 'chang': 4,\n",
       " 'character': 0,\n",
       " 'choic': 0,\n",
       " 'classif': 0,\n",
       " 'clean': 0,\n",
       " 'clear': 0,\n",
       " 'clearest': 0,\n",
       " 'clearli': 1,\n",
       " 'climat': 2,\n",
       " 'clime': 0,\n",
       " 'close': 0,\n",
       " 'cluster': 0,\n",
       " 'co': 0,\n",
       " 'co2': 0,\n",
       " 'coars': 1,\n",
       " 'colder': 0,\n",
       " 'coleoptera': 0,\n",
       " 'collat': 0,\n",
       " 'combin': 0,\n",
       " 'common': 0,\n",
       " 'commun': 0,\n",
       " 'compar': 0,\n",
       " 'comparison': 0,\n",
       " 'complement': 1,\n",
       " 'comprehens': 0,\n",
       " 'concept': 0,\n",
       " 'conclud': 0,\n",
       " 'conclus': 1,\n",
       " 'concurr': 0,\n",
       " 'condit': 0,\n",
       " 'confirm': 0,\n",
       " 'congruent': 0,\n",
       " 'consequ': 0,\n",
       " 'conserv': 0,\n",
       " 'consider': 0,\n",
       " 'consist': 0,\n",
       " 'constraint': 0,\n",
       " 'continu': 1,\n",
       " 'contrast': 0,\n",
       " 'contribut': 4,\n",
       " 'control': 0,\n",
       " 'convent': 0,\n",
       " 'convers': 0,\n",
       " 'cop21': 0,\n",
       " 'correl': 0,\n",
       " 'could': 1,\n",
       " 'countri': 0,\n",
       " 'cover': 1,\n",
       " 'crop': 0,\n",
       " 'cubic': 1,\n",
       " 'cultiv': 0,\n",
       " 'current': 0,\n",
       " 'data': 2,\n",
       " 'date': 0,\n",
       " 'day': 0,\n",
       " 'decad': 0,\n",
       " 'declar': 0,\n",
       " 'declin': 0,\n",
       " 'decoupl': 0,\n",
       " 'deep': 0,\n",
       " 'defin': 1,\n",
       " 'degrad': 0,\n",
       " 'degre': 0,\n",
       " 'demograph': 0,\n",
       " 'depend': 0,\n",
       " 'depth': 0,\n",
       " 'descript': 0,\n",
       " 'desicc': 0,\n",
       " 'determin': 0,\n",
       " 'develop': 0,\n",
       " 'devis': 0,\n",
       " 'dietari': 0,\n",
       " 'differ': 0,\n",
       " 'differenti': 0,\n",
       " 'dioxid': 0,\n",
       " 'dipol': 0,\n",
       " 'direct': 0,\n",
       " 'disappear': 1,\n",
       " 'discuss': 0,\n",
       " 'distinct': 1,\n",
       " 'distribut': 1,\n",
       " 'domin': 0,\n",
       " 'dramat': 0,\n",
       " 'draw': 0,\n",
       " 'drier': 0,\n",
       " 'driest': 0,\n",
       " 'driver': 0,\n",
       " 'dung': 0,\n",
       " 'durat': 0,\n",
       " 'dynam': 0,\n",
       " 'earli': 0,\n",
       " 'east': 0,\n",
       " 'eastern': 0,\n",
       " 'ecolog': 0,\n",
       " 'econom': 0,\n",
       " 'ecosystem': 0,\n",
       " 'effect': 0,\n",
       " 'emerg': 0,\n",
       " 'emiss': 0,\n",
       " 'employ': 0,\n",
       " 'enabl': 0,\n",
       " 'encroach': 0,\n",
       " 'energi': 0,\n",
       " 'enhanc': 0,\n",
       " 'ensur': 0,\n",
       " 'entiti': 0,\n",
       " 'environ': 0,\n",
       " 'environment': 0,\n",
       " 'ephemeroptera': 0,\n",
       " 'equit': 0,\n",
       " 'equiti': 0,\n",
       " 'equival': 3,\n",
       " 'estim': 3,\n",
       " 'etc': 0,\n",
       " 'evalu': 0,\n",
       " 'even': 0,\n",
       " 'evolut': 0,\n",
       " 'evolutionari': 0,\n",
       " 'examin': 0,\n",
       " 'exce': 1,\n",
       " 'experienc': 0,\n",
       " 'explain': 0,\n",
       " 'explanatori': 0,\n",
       " 'explor': 0,\n",
       " 'exploratori': 0,\n",
       " 'extinct': 0,\n",
       " 'extrapol': 1,\n",
       " 'factor': 0,\n",
       " 'farm': 0,\n",
       " 'farmer': 0,\n",
       " 'fertil': 0,\n",
       " 'fertilis': 0,\n",
       " 'field': 0,\n",
       " 'first': 0,\n",
       " 'five': 0,\n",
       " 'fluctuat': 0,\n",
       " 'focu': 0,\n",
       " 'focus': 0,\n",
       " 'fold': 0,\n",
       " 'follow': 0,\n",
       " 'food': 0,\n",
       " 'formul': 0,\n",
       " 'fossil': 0,\n",
       " 'four': 0,\n",
       " 'framework': 0,\n",
       " 'french': 0,\n",
       " 'fuel': 0,\n",
       " 'fulli': 0,\n",
       " 'function': 0,\n",
       " 'futur': 0,\n",
       " 'g': 0,\n",
       " 'gain': 0,\n",
       " 'gap': 0,\n",
       " 'gase': 0,\n",
       " 'generalist': 0,\n",
       " 'geodet': 1,\n",
       " 'geograph': 0,\n",
       " 'ghg': 0,\n",
       " 'gigatonn': 1,\n",
       " 'given': 0,\n",
       " 'glacier': 10,\n",
       " 'glaciolog': 1,\n",
       " 'global': 4,\n",
       " 'globe': 0,\n",
       " 'goal': 0,\n",
       " 'graphic': 0,\n",
       " 'grassland': 0,\n",
       " 'gravimetri': 2,\n",
       " 'greenhous': 0,\n",
       " 'greenland': 2,\n",
       " 'ground': 0,\n",
       " 'group': 0,\n",
       " 'guard': 0,\n",
       " 'habitat': 0,\n",
       " 'healthi': 0,\n",
       " 'heavili': 1,\n",
       " 'heterogen': 1,\n",
       " 'hierarch': 0,\n",
       " 'highlight': 0,\n",
       " 'histor': 0,\n",
       " 'histori': 0,\n",
       " 'holocen': 0,\n",
       " 'hope': 0,\n",
       " 'horizon': 0,\n",
       " 'howev': 0,\n",
       " 'huge': 0,\n",
       " 'human': 0,\n",
       " 'hundr': 1,\n",
       " 'hydro': 0,\n",
       " 'hymenoptera': 0,\n",
       " 'iberia': 0,\n",
       " 'ice': 3,\n",
       " 'icon': 1,\n",
       " 'identifi': 0,\n",
       " 'iii': 0,\n",
       " 'illustr': 0,\n",
       " 'immedi': 0,\n",
       " 'impact': 0,\n",
       " 'implement': 0,\n",
       " 'impli': 0,\n",
       " 'implic': 0,\n",
       " 'import': 0,\n",
       " 'importantli': 0,\n",
       " 'improv': 0,\n",
       " 'includ': 0,\n",
       " 'increas': 0,\n",
       " 'increasingli': 0,\n",
       " 'index': 0,\n",
       " 'indic': 1,\n",
       " 'induc': 0,\n",
       " 'initi': 0,\n",
       " 'innov': 0,\n",
       " 'input': 0,\n",
       " 'insect': 0,\n",
       " 'intens': 0,\n",
       " 'intergovernment': 1,\n",
       " 'intern': 0,\n",
       " 'interplay': 0,\n",
       " 'interpol': 1,\n",
       " 'interpret': 0,\n",
       " 'introduc': 0,\n",
       " 'irrig': 0,\n",
       " 'isotop': 0,\n",
       " 'itali': 0,\n",
       " 'iv': 0,\n",
       " 'justifi': 0,\n",
       " 'key': 0,\n",
       " 'kilometr': 2,\n",
       " 'knowledg': 0,\n",
       " 'lake': 0,\n",
       " 'land': 0,\n",
       " 'landscap': 0,\n",
       " 'larg': 0,\n",
       " 'larger': 1,\n",
       " 'last': 0,\n",
       " 'late': 0,\n",
       " 'latter': 0,\n",
       " 'lazi': 0,\n",
       " 'lead': 0,\n",
       " 'left': 0,\n",
       " 'lepidoptera': 0,\n",
       " 'levant': 0,\n",
       " 'level': 7,\n",
       " 'lever': 0,\n",
       " 'like': 0,\n",
       " 'limit': 1,\n",
       " 'link': 0,\n",
       " 'literatur': 0,\n",
       " 'local': 0,\n",
       " 'long': 0,\n",
       " 'loss': 4,\n",
       " 'lost': 0,\n",
       " 'lower': 0,\n",
       " 'luxuri': 0,\n",
       " 'macroecolog': 0,\n",
       " 'macroevolutionari': 0,\n",
       " 'made': 0,\n",
       " 'maghreb': 0,\n",
       " 'main': 0,\n",
       " 'mainli': 0,\n",
       " 'maintain': 0,\n",
       " 'major': 0,\n",
       " 'manag': 0,\n",
       " 'mani': 0,\n",
       " 'marin': 0,\n",
       " 'markedli': 0,\n",
       " 'market': 0,\n",
       " 'mass': 5,\n",
       " 'matter': 0,\n",
       " 'maxim': 0,\n",
       " 'maximum': 0,\n",
       " 'may': 1,\n",
       " 'mean': 1,\n",
       " 'measur': 1,\n",
       " 'mechan': 0,\n",
       " 'mechanist': 0,\n",
       " 'mediterranean': 0,\n",
       " 'method': 0,\n",
       " 'metr': 3,\n",
       " 'metric': 0,\n",
       " 'microbi': 0,\n",
       " 'microorgan': 0,\n",
       " 'mid': 0,\n",
       " 'millenni': 0,\n",
       " 'millennia': 0,\n",
       " 'millimetr': 2,\n",
       " 'minor': 0,\n",
       " 'mitig': 0,\n",
       " 'model': 0,\n",
       " 'morocco': 0,\n",
       " 'mountain': 2,\n",
       " 'multidimension': 0,\n",
       " 'multipl': 1,\n",
       " 'multipurpos': 0,\n",
       " 'nation': 0,\n",
       " 'natur': 0,\n",
       " 'necessari': 0,\n",
       " 'need': 0,\n",
       " 'neg': 0,\n",
       " 'neolith': 0,\n",
       " 'net': 0,\n",
       " 'next': 0,\n",
       " 'nich': 0,\n",
       " 'nmd': 0,\n",
       " 'norm': 0,\n",
       " 'north': 0,\n",
       " 'notabl': 0,\n",
       " 'number': 1,\n",
       " 'numer': 0,\n",
       " 'nutrient': 0,\n",
       " 'nutrit': 0,\n",
       " 'observ': 3,\n",
       " 'occupi': 0,\n",
       " 'occur': 0,\n",
       " 'odonata': 0,\n",
       " 'offer': 0,\n",
       " 'often': 1,\n",
       " 'ojcv': 0,\n",
       " 'one': 0,\n",
       " 'opportun': 0,\n",
       " 'option': 0,\n",
       " 'order': 0,\n",
       " 'organ': 0,\n",
       " 'origin': 0,\n",
       " 'oscil': 0,\n",
       " 'other': 0,\n",
       " 'outlin': 0,\n",
       " 'overal': 0,\n",
       " 'overlap': 1,\n",
       " 'palaeoclim': 0,\n",
       " 'palynolog': 0,\n",
       " 'pan': 0,\n",
       " 'panel': 1,\n",
       " 'paper': 0,\n",
       " 'pari': 0,\n",
       " 'particular': 0,\n",
       " 'particularli': 0,\n",
       " 'past': 2,\n",
       " 'pathogen': 0,\n",
       " 'pattern': 0,\n",
       " 'peatland': 0,\n",
       " 'peopl': 0,\n",
       " 'period': 0,\n",
       " 'perman': 0,\n",
       " 'perspect': 0,\n",
       " 'pesticid': 0,\n",
       " 'phenomena': 0,\n",
       " 'physiolog': 0,\n",
       " 'plan': 0,\n",
       " 'plecoptera': 0,\n",
       " 'pledg': 0,\n",
       " 'point': 1,\n",
       " 'polit': 0,\n",
       " 'pollen': 0,\n",
       " 'pollut': 0,\n",
       " 'poor': 0,\n",
       " 'popul': 0,\n",
       " 'possibl': 0,\n",
       " 'potenti': 1,\n",
       " 'practic': 0,\n",
       " 'predict': 0,\n",
       " 'present': 2,\n",
       " 'presuppos': 0,\n",
       " 'previous': 1,\n",
       " 'price': 0,\n",
       " 'primarili': 0,\n",
       " 'prior': 0,\n",
       " 'priorit': 0,\n",
       " 'probabl': 0,\n",
       " 'process': 0,\n",
       " 'product': 0,\n",
       " 'profit': 0,\n",
       " 'progress': 0,\n",
       " 'promin': 0,\n",
       " 'proport': 0,\n",
       " 'propos': 0,\n",
       " 'provid': 0,\n",
       " 'proxi': 0,\n",
       " 'punctuat': 0,\n",
       " 'pure': 0,\n",
       " 'put': 0,\n",
       " 'question': 0,\n",
       " 'radiocarbon': 0,\n",
       " 'rais': 0,\n",
       " 'rang': 4,\n",
       " 'rapid': 0,\n",
       " 'ratchet': 0,\n",
       " 'rate': 2,\n",
       " 'recent': 0,\n",
       " 'reconstruct': 0,\n",
       " 'record': 0,\n",
       " 'recoveri': 0,\n",
       " 'reduc': 0,\n",
       " 'reduct': 0,\n",
       " 'refer': 0,\n",
       " 'reflect': 0,\n",
       " 'regard': 0,\n",
       " 'region': 5,\n",
       " 'regret': 0,\n",
       " 'rel': 0,\n",
       " 'relationship': 0,\n",
       " 'relev': 0,\n",
       " 'relianc': 0,\n",
       " 'remain': 0,\n",
       " 'remedi': 0,\n",
       " 'remov': 0,\n",
       " 'replac': 0,\n",
       " 'report': 2,\n",
       " 'repres': 1,\n",
       " 'requir': 0,\n",
       " 'research': 0,\n",
       " 'resili': 0,\n",
       " 'resolut': 1,\n",
       " 'respect': 1,\n",
       " 'respons': 0,\n",
       " 'result': 3,\n",
       " 'rethink': 0,\n",
       " 'retreat': 1,\n",
       " 'retrodict': 0,\n",
       " 'reveal': 0,\n",
       " 'revers': 0,\n",
       " 'review': 0,\n",
       " 'rise': 4,\n",
       " 'role': 0,\n",
       " 'roman': 0,\n",
       " 'root': 0,\n",
       " 'runoff': 1,\n",
       " 'rural': 0,\n",
       " 'safeguard': 0,\n",
       " 'satellit': 2,\n",
       " 'scalar': 0,\n",
       " 'scale': 0,\n",
       " 'scarc': 1,\n",
       " 'score': 0,\n",
       " 'sdg': 0,\n",
       " 'second': 0,\n",
       " 'secur': 0,\n",
       " 'seek': 0,\n",
       " 'seem': 0,\n",
       " 'sequenc': 0,\n",
       " 'sequestr': 0,\n",
       " 'seri': 1,\n",
       " 'seriou': 0,\n",
       " 'servic': 0,\n",
       " 'session': 0,\n",
       " 'set': 0,\n",
       " 'settlement': 0,\n",
       " 'seven': 0,\n",
       " 'sever': 0,\n",
       " 'shape': 0,\n",
       " 'sheet': 3,\n",
       " 'shift': 0,\n",
       " 'show': 1,\n",
       " 'significantli': 0,\n",
       " 'similar': 0,\n",
       " 'sinc': 0,\n",
       " 'singl': 0,\n",
       " 'site': 0,\n",
       " 'situ': 1,\n",
       " 'six': 0,\n",
       " 'slice': 0,\n",
       " 'slow': 0,\n",
       " 'small': 1,\n",
       " 'soc': 0,\n",
       " 'social': 0,\n",
       " 'socio': 0,\n",
       " 'soil': 0,\n",
       " 'solid': 0,\n",
       " 'sourc': 0,\n",
       " 'south': 0,\n",
       " 'southern': 0,\n",
       " 'span': 0,\n",
       " 'spatial': 1,\n",
       " 'spatiotempor': 1,\n",
       " 'spd': 0,\n",
       " 'speci': 0,\n",
       " 'specialist': 0,\n",
       " 'specif': 1,\n",
       " 'squar': 1,\n",
       " 'stabil': 0,\n",
       " 'stabl': 0,\n",
       " 'start': 0,\n",
       " 'statist': 1,\n",
       " 'step': 0,\n",
       " 'stewardship': 0,\n",
       " 'still': 0,\n",
       " 'stock': 0,\n",
       " 'storag': 0,\n",
       " 'store': 0,\n",
       " 'stress': 0,\n",
       " 'struggl': 0,\n",
       " 'studi': 0,\n",
       " 'subsist': 0,\n",
       " 'substanti': 0,\n",
       " 'substitut': 0,\n",
       " 'suggest': 1,\n",
       " 'sum': 0,\n",
       " 'support': 0,\n",
       " 'surprisingli': 0,\n",
       " 'survey': 0,\n",
       " 'sustain': 0,\n",
       " 'synthesi': 0,\n",
       " 'synthet': 0,\n",
       " 'system': 0,\n",
       " 'systemat': 0,\n",
       " 'take': 0,\n",
       " 'target': 0,\n",
       " 'taxa': 0,\n",
       " 'technic': 0,\n",
       " 'technolog': 0,\n",
       " 'temper': 0,\n",
       " 'tempor': 0,\n",
       " 'tension': 0,\n",
       " 'term': 0,\n",
       " 'terrestri': 0,\n",
       " 'theori': 0,\n",
       " 'therefor': 0,\n",
       " 'thin': 1,\n",
       " 'third': 0,\n",
       " 'though': 0,\n",
       " 'threaten': 0,\n",
       " 'three': 0,\n",
       " 'throughout': 0,\n",
       " 'tillag': 0,\n",
       " 'time': 0,\n",
       " 'toler': 0,\n",
       " 'tool': 0,\n",
       " 'top': 0,\n",
       " 'total': 2,\n",
       " 'trade': 0,\n",
       " 'trajectori': 0,\n",
       " 'transform': 0,\n",
       " 'translat': 0,\n",
       " 'tree': 0,\n",
       " 'trend': 0,\n",
       " 'trichoptera': 0,\n",
       " 'tropic': 0,\n",
       " 'turkey': 0,\n",
       " 'two': 0,\n",
       " 'type': 0,\n",
       " 'uncertainti': 1,\n",
       " 'undergo': 0,\n",
       " 'underli': 0,\n",
       " 'underlin': 0,\n",
       " 'understand': 0,\n",
       " 'unfccc': 0,\n",
       " 'unit': 0,\n",
       " 'unknown': 1,\n",
       " 'upon': 0,\n",
       " 'urban': 0,\n",
       " 'urbanis': 0,\n",
       " 'urgent': 0,\n",
       " 'usag': 0,\n",
       " 'use': 1,\n",
       " 'vacant': 0,\n",
       " 'variabl': 0,\n",
       " 'veget': 0,\n",
       " 'versu': 0,\n",
       " 'vision': 0,\n",
       " 'vital': 0,\n",
       " 'volum': 1,\n",
       " 'voluntari': 0,\n",
       " 'warm': 0,\n",
       " 'water': 1,\n",
       " 'well': 2,\n",
       " 'west': 0,\n",
       " 'western': 0,\n",
       " 'wetland': 0,\n",
       " 'wetter': 0,\n",
       " 'wherea': 0,\n",
       " 'whole': 0,\n",
       " 'window': 0,\n",
       " 'within': 0,\n",
       " 'wood': 0,\n",
       " 'woodland': 0,\n",
       " 'work': 0,\n",
       " 'world': 0,\n",
       " 'worldwid': 0,\n",
       " 'would': 0,\n",
       " 'year': 2,\n",
       " 'yield': 0,\n",
       " 'yr': 0,\n",
       " 'zonal': 0,\n",
       " 'zone': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e.g.\n",
    "tf_vector['Lab5_file7.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Now create a function that takes a query, and based on the list of terms and the dictionary of data, returns the top 3 ranked documents. For your ranking algorithm, implement tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('biom', 1.0),\n",
       " ('key', 1.0),\n",
       " ('commun', 0.7686217868402407),\n",
       " ('ecolog', 0.7686217868402407),\n",
       " ('biogeograph', 1.0),\n",
       " ('concept', 1.0),\n",
       " ('profit', 1.0),\n",
       " ('overal', 0.6769924925288455),\n",
       " ('progress', 1.0),\n",
       " ('punctuat', 1.0),\n",
       " ('two', 1.0),\n",
       " ('major', 0.6769924925288455),\n",
       " ('innov', 1.0),\n",
       " ('shift', 0.7686217868402407),\n",
       " ('focu', 0.7686217868402407),\n",
       " ('pure', 1.0),\n",
       " ('pattern', 0.7686217868402407),\n",
       " ('descript', 1.0),\n",
       " ('understand', 0.7686217868402407),\n",
       " ('function', 1.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate idf for each unique term\n",
    "idf = dict(Counter(all_terms))\n",
    "for key, value in idf.items():\n",
    "    #idf[key] = math.log(N/value)\n",
    "    idf[key] = 1/(1+math.log10(value))\n",
    "list(idf.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lab5_file9.txt': 0.520637044798296,\n",
       " 'Lab5_file8.txt': 0.5619956175615656,\n",
       " 'Lab5_file6.txt': 0.4658088176612899,\n",
       " 'Lab5_file7.txt': 0.5516025866068375,\n",
       " 'Lab5_file5.txt': 0.5202988668353199,\n",
       " 'Lab5_file4.txt': 0.49288907169886015,\n",
       " 'Lab5_file1.txt': 0.5331812226792337,\n",
       " 'Lab5_file3.txt': 0.5328767932745728,\n",
       " 'Lab5_file2.txt': 0.4595258993332256}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate tf-idf scores for each document\n",
    "tf_idf = {}\n",
    "def score(files_dict):\n",
    "    for key in list(mapping_dict.values()):\n",
    "        tf_idf[key] = sum([idf[each]*files_dict[key]['tf'][each] for each in list(idf.keys())\n",
    "                           if each in list(files_dict[key]['tf'].keys())])\n",
    "    return tf_idf\n",
    "tf_idf = score(files_dict)\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ranking = sorted([(value,key) for (key,value) in tf_idf.items()],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5619956175615656, 'Lab5_file8.txt')\n",
      "(0.5516025866068375, 'Lab5_file7.txt')\n",
      "(0.5331812226792337, 'Lab5_file1.txt')\n"
     ]
    }
   ],
   "source": [
    "#top 3 ranked documents\n",
    "for each in ranking[:3]:\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
