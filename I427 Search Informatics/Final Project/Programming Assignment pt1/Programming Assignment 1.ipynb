{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer \n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer() \n",
    "def words_count(file_name):\n",
    "    with open (file_name,'r') as md_file:\n",
    "        content = md_file.read()\n",
    "    #remove punctuation\n",
    "    content = re.sub('[^A-Za-z0-9]+', ' ', content)\n",
    "    count = len(content)\n",
    "    content = nltk.word_tokenize(content.lower())\n",
    "    #remove stopwords\n",
    "    content = [word for word in content if not word in stopwords.words()]\n",
    "    for i in range(len(content)):\n",
    "        #stemming words\n",
    "        content[i] = ps.stem(content[i])\n",
    "    file_dict = dict(Counter(content))\n",
    "    for key, value in file_dict.items():\n",
    "        #norm tfs\n",
    "        file_dict[key] = value/count\n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_count_f(folder_path):\n",
    "    dirs = os.listdir(folder_path)\n",
    "    file_dict = {}\n",
    "    for file in dirs:\n",
    "        #filter out trash file \n",
    "        if 'txt' in file:\n",
    "            file_dict[file] = words_count(file)\n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dict = words_count_f('/Users/mac/Documents/I427/pa1/')\n",
    "#value_dict['slyfox.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a new function return mapping_dict, contains index number and txt file names\n",
    "def return_file(folder_path):\n",
    "    dirs = os.listdir(folder_path)\n",
    "    mapping_dict = dict(enumerate(dirs))\n",
    "    return mapping_dict\n",
    "\n",
    "mapping_dict = {}\n",
    "\n",
    "#create an empty dict as argument \n",
    "inv_index = {}\n",
    "\n",
    "def inv_indexer(mapping_dict, value_dict, inv_index):\n",
    "    for key in value_dict.keys():\n",
    "        if key not in mapping_dict.values():\n",
    "            if not mapping_dict.keys():\n",
    "                #the first entry, start with 0\n",
    "                mapping_dict[1] = key\n",
    "            else:\n",
    "                #plus one at a time\n",
    "                mapping_dict[int(max(mapping_dict.keys())+1)] = key\n",
    "    for k, subdict in value_dict.items():\n",
    "        for key, value in mapping_dict.items():\n",
    "            #check which txt file it is\n",
    "            if k == value:\n",
    "                #loop through each term and its frequency\n",
    "                for kk, v in subdict.items():\n",
    "                    inv_index.setdefault(kk, {})[key] = v\n",
    "    return inv_index, mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = inv_indexer(mapping_dict, value_dict, inv_index)[1]\n",
    "inv_index_dict = inv_indexer(mapping_dict, value_dict, inv_index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inv_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gim', {1: 0.00015216068167985393}),\n",
       " ('anoth',\n",
       "  {1: 0.00015216068167985393,\n",
       "   4: 0.00025031289111389235,\n",
       "   6: 0.0005291005291005291}),\n",
       " ('cigarett', {1: 0.0006086427267194157}),\n",
       " ('mark', {1: 0.0030432136335970784}),\n",
       " ('extend', {1: 0.00015216068167985393}),\n",
       " ('hand', {1: 0.0004564820450395618, 2: 0.000142025280499929}),\n",
       " ('wait', {1: 0.00015216068167985393, 4: 0.00025031289111389235}),\n",
       " ('jami', {1: 0.002738892270237371}),\n",
       " ('drop',\n",
       "  {1: 0.00030432136335970786,\n",
       "   2: 0.000142025280499929,\n",
       "   4: 0.00025031289111389235,\n",
       "   5: 0.00013281976358082084,\n",
       "   7: 0.00019704433497536947}),\n",
       " ('cancer', {1: 0.00030432136335970786}),\n",
       " ('dave', {1: 0.0025867315885575166}),\n",
       " ('said',\n",
       "  {1: 0.0025867315885575166,\n",
       "   2: 0.0007101264024996449,\n",
       "   4: 0.000750938673341677,\n",
       "   5: 0.0006640988179041042,\n",
       "   7: 0.001379310344827586}),\n",
       " ('look',\n",
       "  {1: 0.0009129640900791236,\n",
       "   2: 0.000142025280499929,\n",
       "   4: 0.000750938673341677,\n",
       "   5: 0.0006640988179041042,\n",
       "   7: 0.00019704433497536947}),\n",
       " ('mind', {1: 0.00015216068167985393, 2: 0.000142025280499929}),\n",
       " ('go',\n",
       "  {1: 0.0007608034083992696,\n",
       "   2: 0.000142025280499929,\n",
       "   3: 0.001902587519025875,\n",
       "   4: 0.00025031289111389235,\n",
       "   5: 0.000796918581484925,\n",
       "   7: 0.00039408866995073894}),\n",
       " ('ahead', {1: 0.00015216068167985393}),\n",
       " ('realli',\n",
       "  {1: 0.00030432136335970786,\n",
       "   2: 0.000284050560999858,\n",
       "   3: 0.000380517503805175,\n",
       "   4: 0.00025031289111389235,\n",
       "   7: 0.00019704433497536947}),\n",
       " ('call',\n",
       "  {1: 0.00015216068167985393,\n",
       "   2: 0.00042607584149978694,\n",
       "   5: 0.0003984592907424625,\n",
       "   7: 0.00019704433497536947}),\n",
       " ('anyway', {1: 0.00015216068167985393}),\n",
       " ('yeah', {1: 0.0010651247717589774})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = take(20, inv_index_dict.items())\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search common terms across files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the term(s) you want to search: drop look said\n",
      "{'drop': {1: 0.00030432136335970786, 2: 0.000142025280499929, 4: 0.00025031289111389235, 5: 0.00013281976358082084, 7: 0.00019704433497536947}, 'look': {1: 0.0009129640900791236, 2: 0.000142025280499929, 4: 0.000750938673341677, 5: 0.0006640988179041042, 7: 0.00019704433497536947}, 'said': {1: 0.0025867315885575166, 2: 0.0007101264024996449, 4: 0.000750938673341677, 5: 0.0006640988179041042, 7: 0.001379310344827586}}\n",
      "blind.txt 0.003804017041996348\n",
      "3pigs.txt 0.001773399014778325\n",
      "3wishes.txt 0.0017521902377972466\n",
      "slyfox.txt 0.001461017399389029\n",
      "beautbst.txt 0.0009941769634995029\n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "sub_dict = {}\n",
    "ranking_dict = {}\n",
    "\n",
    "def search_words(inv_index_dict):\n",
    "    #get user input as a list\n",
    "    user_input = list(input(\"Please enter the term(s) you want to search: \").strip().split())\n",
    "    #check if all input terms exist in the dict\n",
    "    if all(word in inv_index_dict.keys() for word in user_input):\n",
    "        for word in user_input:\n",
    "            #append the list of documents for each term to a large nested list\n",
    "            lst.append([int(k) for k in inv_index_dict[word].keys()])\n",
    "            #create a sub dict only contains terms we search\n",
    "            sub_dict[word] = inv_index_dict[word]\n",
    "        print(sub_dict)\n",
    "        #find the intersection\n",
    "        result = set.intersection(*[set(x) for x in lst]) \n",
    "        if result:\n",
    "            for each in result:\n",
    "                #use sub dict to sum the ranking values of each common key\n",
    "                ranking_values = sum(d[each] for d in sub_dict.values())\n",
    "                ranking_dict[mapping_dict[each]] = ranking_values\n",
    "            #sort the dict by the ranking values in descending order\n",
    "            for k in sorted(ranking_dict, key=ranking_dict.get, reverse=True):\n",
    "                print(k, ranking_dict[k])\n",
    "        else:\n",
    "            print(\"Common documents don't exist.\")\n",
    "    else: \n",
    "        print(\"Invalid input! Please try again.\")\n",
    "    \n",
    "search_words(inv_index_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all about tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_q(folder_path):\n",
    "    value_dict = words_count_f(folder_path)\n",
    "    all_terms = []\n",
    "    for each_file in value_dict.values():\n",
    "        full_lst = list(each_file.keys())\n",
    "        for each in full_lst:\n",
    "            all_terms.append(each)\n",
    "    #calculate idf for each unique term\n",
    "    idf = dict(Counter(all_terms))\n",
    "    for key, value in idf.items():\n",
    "        idf[key] = 1/(1+math.log10(value))\n",
    "    mapping_dict = {}\n",
    "    for key in value_dict.keys():\n",
    "        if key not in mapping_dict.values():\n",
    "            if not mapping_dict.keys():\n",
    "                mapping_dict[1] = key\n",
    "            else:\n",
    "                mapping_dict[int(max(mapping_dict.keys())+1)] = key\n",
    "    for key in list(mapping_dict.values()):\n",
    "        tf_idf[key] = sum([idf[each]*value_dict[key][each] for each in list(idf.keys())\n",
    "                           if each in list(value_dict[key].keys())])\n",
    "    user_input = list(input(\"Please enter your query: \").strip().split())\n",
    "    #ranking\n",
    "    for word in user_input:\n",
    "        if 'rank' in word:\n",
    "            ranking = sorted([(value,key) for (key,value) in tf_idf.items()],reverse=True)\n",
    "            for each in ranking:\n",
    "                print(each)\n",
    "    #corresponding tf-idf score\n",
    "    for file in value_dict.keys():\n",
    "        for word in user_input:\n",
    "            if word in file:\n",
    "                sub_dict = {}\n",
    "                sub_dict[file] = tf_idf[file]\n",
    "                for each in sub_dict.items():\n",
    "                    print(each)\n",
    "    #check file with tf-idf score greater than certain number\n",
    "    if '>' in user_input:\n",
    "        for file, score in tf_idf.items():\n",
    "            if score > float(user_input[user_input.index('>')+1]):\n",
    "                zero_dict = {}\n",
    "                zero_dict[file] = score\n",
    "                for each in zero_dict.items():\n",
    "                    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'blind.txt',\n",
       " 2: 'beautbst.txt',\n",
       " 3: 'campfire.txt',\n",
       " 4: '3wishes.txt',\n",
       " 5: 'slyfox.txt',\n",
       " 6: 'aircon.txt',\n",
       " 7: '3pigs.txt'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your query: show ranking\n",
      "(0.08803210333334059, 'slyfox.txt')\n",
      "(0.08006603659217393, 'aircon.txt')\n",
      "(0.07942907218058502, 'blind.txt')\n",
      "(0.07831145407433074, '3pigs.txt')\n",
      "(0.07312373458844192, 'beautbst.txt')\n",
      "(0.0730932215809103, 'campfire.txt')\n",
      "(0.06929237548140457, '3wishes.txt')\n"
     ]
    }
   ],
   "source": [
    "#e.g. 1\n",
    "tf_idf_q('/Users/mac/Documents/I427/pa1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your query: 3 fox\n",
      "('3wishes.txt', 0.06929237548140457)\n",
      "('slyfox.txt', 0.08803210333334059)\n",
      "('3pigs.txt', 0.07831145407433074)\n"
     ]
    }
   ],
   "source": [
    "#e.g. 2\n",
    "tf_idf_q('/Users/mac/Documents/I427/pa1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your query: > 0.077\n",
      "('blind.txt', 0.07942907218058502)\n",
      "('slyfox.txt', 0.08803210333334059)\n",
      "('aircon.txt', 0.08006603659217393)\n",
      "('3pigs.txt', 0.07831145407433074)\n"
     ]
    }
   ],
   "source": [
    "#e.g. 3\n",
    "tf_idf_q('/Users/mac/Documents/I427/pa1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
