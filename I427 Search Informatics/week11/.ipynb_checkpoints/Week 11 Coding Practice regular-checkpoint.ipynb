{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer \n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file and separate each summary\n",
    "with open ('movie_summaries_427lab.txt','r') as md_file:\n",
    "    content = md_file.readlines() \n",
    "    content = [line.strip().split('\\t') for line in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the list to the dictionary \n",
    "file_dict = {}\n",
    "for i in range(len(content)):\n",
    "    file_dict[content[i][0]] = content[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the empty dictionary for term frequency \n",
    "value_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the text and store the tf data\n",
    "for key, value in file_dict.items():\n",
    "    value = re.sub('[^A-Za-z0-9]+', ' ', value)\n",
    "    value = nltk.word_tokenize(value.lower())\n",
    "    count = len(value)\n",
    "    ps = PorterStemmer() \n",
    "    value = [word for word in value if not word in stopwords.words()]\n",
    "    value = [ps.stem(word) for word in value]\n",
    "    words_f = dict(Counter(value))\n",
    "    for kk, v in words_f.items():\n",
    "        words_f[kk] = v/count\n",
    "    value_dict[key] = words_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shlykov': 0.03571428571428571,\n",
       " 'hard': 0.03571428571428571,\n",
       " 'work': 0.03571428571428571,\n",
       " 'taxi': 0.03571428571428571,\n",
       " 'driver': 0.03571428571428571,\n",
       " 'lyosha': 0.03571428571428571,\n",
       " 'saxophonist': 0.03571428571428571,\n",
       " 'develop': 0.03571428571428571,\n",
       " 'bizarr': 0.03571428571428571,\n",
       " 'love': 0.03571428571428571,\n",
       " 'hate': 0.03571428571428571,\n",
       " 'relationship': 0.03571428571428571,\n",
       " 'despit': 0.03571428571428571,\n",
       " 'prejudic': 0.03571428571428571,\n",
       " 'realiz': 0.03571428571428571,\n",
       " 'differ': 0.03571428571428571}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g.\n",
    "value_dict['23890098']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all terms\n",
    "all_terms = []\n",
    "for subdict in value_dict.values():\n",
    "    full_lst = list(subdict.keys())\n",
    "    for each in full_lst:\n",
    "        all_terms.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shlykov', 1.0),\n",
       " ('hard', 0.4201307776703473),\n",
       " ('work', 0.31880429849910086),\n",
       " ('taxi', 0.5117072191244584),\n",
       " ('driver', 0.4269084346677318),\n",
       " ('lyosha', 1.0),\n",
       " ('saxophonist', 0.7686217868402407),\n",
       " ('develop', 0.3812066217497452),\n",
       " ('bizarr', 0.588591910067779),\n",
       " ('love', 0.3118348294100107),\n",
       " ('hate', 0.4595395509441786),\n",
       " ('relationship', 0.3581159490485675),\n",
       " ('despit', 0.3659794626616297),\n",
       " ('prejudic', 0.7686217868402407),\n",
       " ('realiz', 0.3425739114728579),\n",
       " ('differ', 0.3950260036802463),\n",
       " ('nation', 0.4659554245485504),\n",
       " ('panem', 1.0),\n",
       " ('consist', 0.5),\n",
       " ('wealthi', 0.414083244786221)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate idf for each unique term\n",
    "idf = dict(Counter(all_terms))\n",
    "for key, value in idf.items():\n",
    "    #idf[key] = math.log(N/value)\n",
    "    idf[key] = 1/(1+math.log10(value))\n",
    "list(idf.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
